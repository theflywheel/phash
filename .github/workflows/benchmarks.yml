name: Performance Benchmarks

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]
  workflow_dispatch:
  schedule:
    - cron: "0 0 * * 0" # Weekly run on Sunday

jobs:
  benchmark:
    name: Run Benchmarks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0 # Fetch all history for all branches and tags

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: "1.20"
          check-latest: true

      - name: Install dependencies
        run: go get -v ./...

      # Run small benchmarks for quick feedback
      - name: Run small scale benchmarks
        run: |
          go test -v ./bench -run BenchmarkTenThousandKeys > small_benchmark_results.txt
          cat small_benchmark_results.txt

      # Run medium scale benchmarks
      - name: Run medium scale benchmarks
        run: |
          go test -v ./bench -run BenchmarkMillionKeys > medium_benchmark_results.txt
          cat medium_benchmark_results.txt

      # Run UUID benchmark
      - name: Run UUID benchmarks
        run: |
          go test -v ./bench -run BenchmarkUUIDKeys > uuid_benchmark_results.txt
          cat uuid_benchmark_results.txt

      # Run large scale benchmarks only on schedule or manual trigger (not on every PR)
      - name: Run large scale benchmarks
        if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
        run: |
          go test -v ./bench -run BenchmarkTenMillionKeys > large_benchmark_results.txt
          cat large_benchmark_results.txt

      # For PRs, we use the comparison script
      - name: Run PR benchmark comparison
        if: github.event_name == 'pull_request'
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"

          echo "Fetching main branch for comparison..."
          git fetch origin main:main

          echo "PR is comparing branch ${{ github.head_ref }} to main"

          # First, run benchmarks on main branch for baseline
          echo "Creating baseline from main branch..."
          git checkout main
          ./bench/tools/store_benchmark.sh

          # Switch back to PR branch and compare
          echo "Switching back to PR branch and comparing..."
          git checkout ${{ github.sha }}
          ./bench/tools/compare_pr.sh

          # Results will be in the benchmark-comparison.json file

      # Validate benchmark results for PRs and fail if performance degraded
      - name: Validate benchmark improvements
        if: github.event_name == 'pull_request'
        run: |
          # Check if benchmarks have improved or remained stable
          # This script should exit with non-zero status if benchmarks degraded
          ./bench/tools/validate_benchmarks.sh || (echo "::error::Benchmark performance has degraded! See benchmark results for details." && exit 1)

      # Comment on PR with benchmark results
      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');

            try {
              const benchmarkResults = fs.readFileSync('./benchmark-comparison.json', 'utf8');
              const results = JSON.parse(benchmarkResults);
              
              // Generate a formatted comment with benchmark comparison
              let comment = '## Benchmark Results\n\n';
              comment += '| Benchmark | Before | After | Change |\n';
              comment += '|-----------|--------|-------|--------|\n';
              
              // Add each benchmark to the table
              for (const benchmark of results.benchmarks) {
                const beforeValue = benchmark.baseline_ns_per_op.toFixed(2);
                const afterValue = benchmark.current_ns_per_op.toFixed(2);
                const pctChange = benchmark.percent_change.toFixed(2);
                const changeIcon = pctChange <= 0 ? '✅' : '❌';
                
                comment += `| ${benchmark.name} | ${beforeValue}ns | ${afterValue}ns | ${changeIcon} ${pctChange}% |\n`;
              }
              
              comment += '\n### Summary\n';
              comment += results.improved ? 
                '✅ **Benchmarks have improved or remained stable!**\n' : 
                '❌ **Some benchmarks have degraded in performance.**\n';
              
              // Post comment on PR
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            } catch (error) {
              console.error('Error processing benchmark results:', error);
              core.setFailed('Failed to process benchmark results');
            }

      # For main branch pushes and scheduled runs, we just store the benchmark
      - name: Store benchmark results (main branch)
        if: github.event_name != 'pull_request'
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          ./bench/tools/store_benchmark.sh

      - name: Archive benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.sha }}
          path: |
            benchmark_history/
            benchmark-comparison.json
            *_benchmark_results.txt
          retention-days: 90
